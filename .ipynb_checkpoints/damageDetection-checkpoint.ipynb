{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca40dd3-8259-4eac-b3c7-af5416ae4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d341528-af51-48d8-869e-5e92889b455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1840 images belonging to 2 classes.\n",
      "Found 460 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "train_dir = \"dataset/train\"\n",
    "test_dir = \"dataset/test\"\n",
    "\n",
    "# Data augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,         # Normalize pixel values\n",
    "    rotation_range=30,      # Random rotation\n",
    "    width_shift_range=0.2,  # Random horizontal shift\n",
    "    height_shift_range=0.2, # Random vertical shift\n",
    "    shear_range=0.2,        # Shearing\n",
    "    zoom_range=0.2,         # Zooming\n",
    "    horizontal_flip=True,   # Flip horizontally\n",
    "    fill_mode='nearest'     # Fill missing pixels\n",
    ")\n",
    "\n",
    "# Preprocessing for testing data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the datasets\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89a2246-1e07-4ae6-ae9d-0de427b0fc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\hamza\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 770ms/step - accuracy: 0.5106 - loss: 0.9831 - val_accuracy: 0.5500 - val_loss: 0.6855\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 723ms/step - accuracy: 0.5713 - loss: 0.6714 - val_accuracy: 0.6565 - val_loss: 0.6399\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 754ms/step - accuracy: 0.6639 - loss: 0.6423 - val_accuracy: 0.6261 - val_loss: 0.6720\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 767ms/step - accuracy: 0.6596 - loss: 0.6374 - val_accuracy: 0.6891 - val_loss: 0.6238\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 712ms/step - accuracy: 0.6583 - loss: 0.6291 - val_accuracy: 0.6739 - val_loss: 0.6253\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 767ms/step - accuracy: 0.6575 - loss: 0.6149 - val_accuracy: 0.6609 - val_loss: 0.6397\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 722ms/step - accuracy: 0.6512 - loss: 0.6177 - val_accuracy: 0.6826 - val_loss: 0.5998\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 708ms/step - accuracy: 0.6951 - loss: 0.5992 - val_accuracy: 0.7391 - val_loss: 0.5569\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 704ms/step - accuracy: 0.6913 - loss: 0.6059 - val_accuracy: 0.6565 - val_loss: 0.6765\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 712ms/step - accuracy: 0.7232 - loss: 0.5605 - val_accuracy: 0.5913 - val_loss: 0.8020\n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_history = cnn_model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=test_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef62687-137b-45ec-8cb1-ad8c8d30c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_8040\\2309857045.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 716ms/step - accuracy: 0.5696 - loss: 0.8417 - val_accuracy: 0.7739 - val_loss: 0.4532\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 713ms/step - accuracy: 0.7561 - loss: 0.5618 - val_accuracy: 0.7891 - val_loss: 0.4214\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 719ms/step - accuracy: 0.7934 - loss: 0.4544 - val_accuracy: 0.7848 - val_loss: 0.4170\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 718ms/step - accuracy: 0.8056 - loss: 0.4220 - val_accuracy: 0.7978 - val_loss: 0.4005\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 680ms/step - accuracy: 0.8124 - loss: 0.4159 - val_accuracy: 0.8087 - val_loss: 0.3724\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 683ms/step - accuracy: 0.8089 - loss: 0.4123 - val_accuracy: 0.8109 - val_loss: 0.3687\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 678ms/step - accuracy: 0.8229 - loss: 0.4122 - val_accuracy: 0.8130 - val_loss: 0.3700\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 686ms/step - accuracy: 0.8323 - loss: 0.3842 - val_accuracy: 0.8413 - val_loss: 0.3334\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 679ms/step - accuracy: 0.8408 - loss: 0.3911 - val_accuracy: 0.8500 - val_loss: 0.3200\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 694ms/step - accuracy: 0.8403 - loss: 0.3602 - val_accuracy: 0.8130 - val_loss: 0.3695\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "mobilenet_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "mobilenet_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "mobilenet_history = mobilenet_model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=test_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34e45383-ab0a-4f72-8e99-3f87ebd01b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_8040\\3703232714.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 726ms/step - accuracy: 0.5847 - loss: 0.8495 - val_accuracy: 0.7435 - val_loss: 0.4884\n",
      "Epoch 2/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 690ms/step - accuracy: 0.7581 - loss: 0.5262 - val_accuracy: 0.7870 - val_loss: 0.4408\n",
      "Epoch 3/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 675ms/step - accuracy: 0.7883 - loss: 0.4710 - val_accuracy: 0.7804 - val_loss: 0.4393\n",
      "Epoch 4/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 670ms/step - accuracy: 0.8012 - loss: 0.4353 - val_accuracy: 0.8304 - val_loss: 0.3758\n",
      "Epoch 5/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 663ms/step - accuracy: 0.7923 - loss: 0.4242 - val_accuracy: 0.8348 - val_loss: 0.3687\n",
      "Epoch 6/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 666ms/step - accuracy: 0.8172 - loss: 0.4082 - val_accuracy: 0.8500 - val_loss: 0.3504\n",
      "Epoch 7/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 674ms/step - accuracy: 0.8352 - loss: 0.3987 - val_accuracy: 0.8152 - val_loss: 0.3832\n",
      "Epoch 8/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 664ms/step - accuracy: 0.8419 - loss: 0.3939 - val_accuracy: 0.7978 - val_loss: 0.4140\n",
      "Epoch 9/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 674ms/step - accuracy: 0.8354 - loss: 0.3823 - val_accuracy: 0.8217 - val_loss: 0.3592\n",
      "Epoch 10/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 666ms/step - accuracy: 0.8380 - loss: 0.3780 - val_accuracy: 0.8348 - val_loss: 0.3378\n",
      "Epoch 11/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 680ms/step - accuracy: 0.8538 - loss: 0.3437 - val_accuracy: 0.8152 - val_loss: 0.3676\n",
      "Epoch 12/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 677ms/step - accuracy: 0.8586 - loss: 0.3323 - val_accuracy: 0.8174 - val_loss: 0.3514\n",
      "Epoch 13/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 666ms/step - accuracy: 0.8598 - loss: 0.3400 - val_accuracy: 0.8543 - val_loss: 0.3091\n",
      "Epoch 14/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 670ms/step - accuracy: 0.8483 - loss: 0.3534 - val_accuracy: 0.8196 - val_loss: 0.3527\n",
      "Epoch 15/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 668ms/step - accuracy: 0.8521 - loss: 0.3374 - val_accuracy: 0.8217 - val_loss: 0.3572\n",
      "Epoch 16/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 667ms/step - accuracy: 0.8536 - loss: 0.3311 - val_accuracy: 0.8391 - val_loss: 0.3231\n",
      "Epoch 17/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 669ms/step - accuracy: 0.8633 - loss: 0.3208 - val_accuracy: 0.8478 - val_loss: 0.3080\n",
      "Epoch 18/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 683ms/step - accuracy: 0.8665 - loss: 0.3192 - val_accuracy: 0.8609 - val_loss: 0.2975\n",
      "Epoch 19/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 666ms/step - accuracy: 0.8647 - loss: 0.3414 - val_accuracy: 0.8543 - val_loss: 0.2989\n",
      "Epoch 20/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 662ms/step - accuracy: 0.8591 - loss: 0.3304 - val_accuracy: 0.8326 - val_loss: 0.3236\n",
      "Epoch 21/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 670ms/step - accuracy: 0.8750 - loss: 0.3083 - val_accuracy: 0.8413 - val_loss: 0.3146\n",
      "Epoch 22/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 663ms/step - accuracy: 0.8662 - loss: 0.3122 - val_accuracy: 0.8283 - val_loss: 0.3331\n",
      "Epoch 23/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 685ms/step - accuracy: 0.8717 - loss: 0.3004 - val_accuracy: 0.8435 - val_loss: 0.3192\n",
      "Epoch 24/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 687ms/step - accuracy: 0.8600 - loss: 0.3204 - val_accuracy: 0.8478 - val_loss: 0.3167\n",
      "Epoch 25/25\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 668ms/step - accuracy: 0.8691 - loss: 0.3087 - val_accuracy: 0.8522 - val_loss: 0.3076\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "mobilenet_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "mobilenet_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "mobilenet_history = mobilenet_model.fit(\n",
    "    train_data,\n",
    "    epochs=25,\n",
    "    validation_data=test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2acdd1d4-18eb-4563-8bc7-a4e5a5af0db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 902ms/step - accuracy: 0.5123 - loss: 0.6999 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 818ms/step - accuracy: 0.5135 - loss: 0.7034 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 821ms/step - accuracy: 0.4832 - loss: 0.7037 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 795ms/step - accuracy: 0.5078 - loss: 0.6958 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 816ms/step - accuracy: 0.5023 - loss: 0.6971 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 863ms/step - accuracy: 0.4917 - loss: 0.6949 - val_accuracy: 0.5000 - val_loss: 0.6964\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 844ms/step - accuracy: 0.4772 - loss: 0.6981 - val_accuracy: 0.4717 - val_loss: 0.6932\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 892ms/step - accuracy: 0.4857 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 895ms/step - accuracy: 0.4989 - loss: 0.6942 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 929ms/step - accuracy: 0.4940 - loss: 0.6948 - val_accuracy: 0.5000 - val_loss: 0.6932\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained EfficientNetB0\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "efficientnet_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "efficientnet_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                           loss='binary_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "efficientnet_history = efficientnet_model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=test_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c263090a-604d-4763-b6eb-ac519b9c0db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_8040\\3810991184.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 729ms/step - accuracy: 0.5907 - loss: 0.7779 - val_accuracy: 0.7761 - val_loss: 0.4443\n",
      "Epoch 2/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 684ms/step - accuracy: 0.7343 - loss: 0.5402 - val_accuracy: 0.7870 - val_loss: 0.4074\n",
      "Epoch 3/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 715ms/step - accuracy: 0.7835 - loss: 0.4624 - val_accuracy: 0.8261 - val_loss: 0.3661\n",
      "Epoch 4/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 678ms/step - accuracy: 0.8025 - loss: 0.4278 - val_accuracy: 0.8630 - val_loss: 0.3330\n",
      "Epoch 5/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 686ms/step - accuracy: 0.8039 - loss: 0.4265 - val_accuracy: 0.8217 - val_loss: 0.3524\n",
      "Epoch 6/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 678ms/step - accuracy: 0.8290 - loss: 0.4020 - val_accuracy: 0.8283 - val_loss: 0.3429\n",
      "Epoch 7/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 673ms/step - accuracy: 0.8216 - loss: 0.4005 - val_accuracy: 0.8478 - val_loss: 0.3258\n",
      "Epoch 8/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 664ms/step - accuracy: 0.8340 - loss: 0.3780 - val_accuracy: 0.8391 - val_loss: 0.3366\n",
      "Epoch 9/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 665ms/step - accuracy: 0.8193 - loss: 0.3912 - val_accuracy: 0.8196 - val_loss: 0.3473\n",
      "Epoch 10/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 669ms/step - accuracy: 0.8371 - loss: 0.3695 - val_accuracy: 0.8609 - val_loss: 0.3140\n",
      "Epoch 11/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 681ms/step - accuracy: 0.8397 - loss: 0.3621 - val_accuracy: 0.8435 - val_loss: 0.3221\n",
      "Epoch 12/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 663ms/step - accuracy: 0.8405 - loss: 0.3694 - val_accuracy: 0.8522 - val_loss: 0.3164\n",
      "Epoch 13/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 667ms/step - accuracy: 0.8361 - loss: 0.3706 - val_accuracy: 0.8696 - val_loss: 0.2944\n",
      "Epoch 14/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 670ms/step - accuracy: 0.8634 - loss: 0.3428 - val_accuracy: 0.8283 - val_loss: 0.3470\n",
      "Epoch 15/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 675ms/step - accuracy: 0.8421 - loss: 0.3571 - val_accuracy: 0.8717 - val_loss: 0.2913\n",
      "Epoch 16/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 873ms/step - accuracy: 0.8628 - loss: 0.3467 - val_accuracy: 0.8565 - val_loss: 0.3124\n",
      "Epoch 17/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 661ms/step - accuracy: 0.8660 - loss: 0.3121 - val_accuracy: 0.8522 - val_loss: 0.3060\n",
      "Epoch 18/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 668ms/step - accuracy: 0.8538 - loss: 0.3269 - val_accuracy: 0.8391 - val_loss: 0.3312\n",
      "Epoch 19/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 672ms/step - accuracy: 0.8479 - loss: 0.3604 - val_accuracy: 0.8326 - val_loss: 0.3354\n",
      "Epoch 20/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 666ms/step - accuracy: 0.8544 - loss: 0.3439 - val_accuracy: 0.8565 - val_loss: 0.3002\n",
      "Epoch 21/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 674ms/step - accuracy: 0.8617 - loss: 0.3168 - val_accuracy: 0.8630 - val_loss: 0.3012\n",
      "Epoch 22/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 673ms/step - accuracy: 0.8622 - loss: 0.3397 - val_accuracy: 0.8174 - val_loss: 0.3638\n",
      "Epoch 23/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 753ms/step - accuracy: 0.8795 - loss: 0.3063 - val_accuracy: 0.8783 - val_loss: 0.2666\n",
      "Epoch 24/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 670ms/step - accuracy: 0.8834 - loss: 0.2938 - val_accuracy: 0.8543 - val_loss: 0.3165\n",
      "Epoch 25/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 673ms/step - accuracy: 0.8764 - loss: 0.2982 - val_accuracy: 0.8587 - val_loss: 0.3060\n",
      "Epoch 26/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 644ms/step - accuracy: 0.8674 - loss: 0.3123 - val_accuracy: 0.8717 - val_loss: 0.2900\n",
      "Epoch 27/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 657ms/step - accuracy: 0.8701 - loss: 0.2926 - val_accuracy: 0.8500 - val_loss: 0.3135\n",
      "Epoch 28/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 642ms/step - accuracy: 0.8837 - loss: 0.2932 - val_accuracy: 0.8457 - val_loss: 0.3184\n",
      "Epoch 29/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 653ms/step - accuracy: 0.8866 - loss: 0.2926 - val_accuracy: 0.8652 - val_loss: 0.2968\n",
      "Epoch 30/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 653ms/step - accuracy: 0.8891 - loss: 0.2905 - val_accuracy: 0.8696 - val_loss: 0.2818\n",
      "Epoch 31/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 638ms/step - accuracy: 0.8786 - loss: 0.3026 - val_accuracy: 0.8674 - val_loss: 0.3009\n",
      "Epoch 32/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 647ms/step - accuracy: 0.8655 - loss: 0.3066 - val_accuracy: 0.8413 - val_loss: 0.3259\n",
      "Epoch 33/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 669ms/step - accuracy: 0.8822 - loss: 0.2778 - val_accuracy: 0.8630 - val_loss: 0.2957\n",
      "Epoch 34/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 642ms/step - accuracy: 0.8714 - loss: 0.3002 - val_accuracy: 0.8543 - val_loss: 0.3126\n",
      "Epoch 35/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 903ms/step - accuracy: 0.8826 - loss: 0.2914 - val_accuracy: 0.8630 - val_loss: 0.2923\n",
      "Epoch 36/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 810ms/step - accuracy: 0.8920 - loss: 0.2542 - val_accuracy: 0.8543 - val_loss: 0.3105\n",
      "Epoch 37/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 667ms/step - accuracy: 0.8652 - loss: 0.3124 - val_accuracy: 0.8783 - val_loss: 0.2826\n",
      "Epoch 38/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 662ms/step - accuracy: 0.8834 - loss: 0.2824 - val_accuracy: 0.8609 - val_loss: 0.3009\n",
      "Epoch 39/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 652ms/step - accuracy: 0.8861 - loss: 0.2759 - val_accuracy: 0.8435 - val_loss: 0.3208\n",
      "Epoch 40/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 647ms/step - accuracy: 0.8844 - loss: 0.2838 - val_accuracy: 0.8652 - val_loss: 0.2893\n",
      "Epoch 41/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 690ms/step - accuracy: 0.8777 - loss: 0.2743 - val_accuracy: 0.8891 - val_loss: 0.2752\n",
      "Epoch 42/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 656ms/step - accuracy: 0.8623 - loss: 0.2984 - val_accuracy: 0.8652 - val_loss: 0.2901\n",
      "Epoch 43/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 672ms/step - accuracy: 0.8856 - loss: 0.2875 - val_accuracy: 0.8500 - val_loss: 0.3088\n",
      "Epoch 44/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 711ms/step - accuracy: 0.8838 - loss: 0.2713 - val_accuracy: 0.8717 - val_loss: 0.2793\n",
      "Epoch 45/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 671ms/step - accuracy: 0.8697 - loss: 0.2961 - val_accuracy: 0.8565 - val_loss: 0.2894\n",
      "Epoch 46/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 651ms/step - accuracy: 0.8808 - loss: 0.2770 - val_accuracy: 0.8413 - val_loss: 0.3357\n",
      "Epoch 47/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 680ms/step - accuracy: 0.8918 - loss: 0.2795 - val_accuracy: 0.8587 - val_loss: 0.2961\n",
      "Epoch 48/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 649ms/step - accuracy: 0.9048 - loss: 0.2467 - val_accuracy: 0.8717 - val_loss: 0.2731\n",
      "Epoch 49/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 647ms/step - accuracy: 0.8891 - loss: 0.2536 - val_accuracy: 0.8478 - val_loss: 0.3233\n",
      "Epoch 50/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 646ms/step - accuracy: 0.8790 - loss: 0.2813 - val_accuracy: 0.8565 - val_loss: 0.2929\n",
      "Epoch 51/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 653ms/step - accuracy: 0.8984 - loss: 0.2481 - val_accuracy: 0.8587 - val_loss: 0.3061\n",
      "Epoch 52/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 647ms/step - accuracy: 0.8967 - loss: 0.2578 - val_accuracy: 0.8522 - val_loss: 0.3156\n",
      "Epoch 53/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 672ms/step - accuracy: 0.8801 - loss: 0.2730 - val_accuracy: 0.8609 - val_loss: 0.3061\n",
      "Epoch 54/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 654ms/step - accuracy: 0.9051 - loss: 0.2520 - val_accuracy: 0.8435 - val_loss: 0.3246\n",
      "Epoch 55/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 647ms/step - accuracy: 0.8895 - loss: 0.2657 - val_accuracy: 0.8804 - val_loss: 0.2729\n",
      "Epoch 56/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 674ms/step - accuracy: 0.9054 - loss: 0.2347 - val_accuracy: 0.8674 - val_loss: 0.2941\n",
      "Epoch 57/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 651ms/step - accuracy: 0.9049 - loss: 0.2394 - val_accuracy: 0.8587 - val_loss: 0.3055\n",
      "Epoch 58/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 669ms/step - accuracy: 0.9085 - loss: 0.2354 - val_accuracy: 0.8717 - val_loss: 0.2905\n",
      "Epoch 59/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 657ms/step - accuracy: 0.8961 - loss: 0.2471 - val_accuracy: 0.8674 - val_loss: 0.2862\n",
      "Epoch 60/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 666ms/step - accuracy: 0.8854 - loss: 0.2588 - val_accuracy: 0.8696 - val_loss: 0.2812\n",
      "Epoch 61/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 674ms/step - accuracy: 0.8876 - loss: 0.2693 - val_accuracy: 0.8543 - val_loss: 0.3120\n",
      "Epoch 62/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 675ms/step - accuracy: 0.9009 - loss: 0.2492 - val_accuracy: 0.8457 - val_loss: 0.3157\n",
      "Epoch 63/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 655ms/step - accuracy: 0.8991 - loss: 0.2404 - val_accuracy: 0.8565 - val_loss: 0.3080\n",
      "Epoch 64/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 679ms/step - accuracy: 0.8792 - loss: 0.2493 - val_accuracy: 0.8543 - val_loss: 0.3118\n",
      "Epoch 65/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 650ms/step - accuracy: 0.8982 - loss: 0.2689 - val_accuracy: 0.8587 - val_loss: 0.2973\n",
      "Epoch 66/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 676ms/step - accuracy: 0.8866 - loss: 0.2507 - val_accuracy: 0.8522 - val_loss: 0.2956\n",
      "Epoch 67/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 668ms/step - accuracy: 0.8854 - loss: 0.2670 - val_accuracy: 0.8435 - val_loss: 0.3240\n",
      "Epoch 68/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 650ms/step - accuracy: 0.9073 - loss: 0.2247 - val_accuracy: 0.8696 - val_loss: 0.2797\n",
      "Epoch 69/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 680ms/step - accuracy: 0.8924 - loss: 0.2608 - val_accuracy: 0.8522 - val_loss: 0.2976\n",
      "Epoch 70/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 668ms/step - accuracy: 0.8875 - loss: 0.2651 - val_accuracy: 0.8457 - val_loss: 0.3155\n",
      "Epoch 71/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 681ms/step - accuracy: 0.8881 - loss: 0.2638 - val_accuracy: 0.8783 - val_loss: 0.2797\n",
      "Epoch 72/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 673ms/step - accuracy: 0.9022 - loss: 0.2408 - val_accuracy: 0.8783 - val_loss: 0.2727\n",
      "Epoch 73/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 679ms/step - accuracy: 0.8892 - loss: 0.2606 - val_accuracy: 0.8804 - val_loss: 0.2700\n",
      "Epoch 74/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 653ms/step - accuracy: 0.9208 - loss: 0.2146 - val_accuracy: 0.8739 - val_loss: 0.2758\n",
      "Epoch 75/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 753ms/step - accuracy: 0.8924 - loss: 0.2701 - val_accuracy: 0.8522 - val_loss: 0.3101\n",
      "Epoch 76/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 770ms/step - accuracy: 0.8851 - loss: 0.2669 - val_accuracy: 0.8587 - val_loss: 0.3004\n",
      "Epoch 77/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 677ms/step - accuracy: 0.9053 - loss: 0.2235 - val_accuracy: 0.8500 - val_loss: 0.3189\n",
      "Epoch 78/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 673ms/step - accuracy: 0.8846 - loss: 0.2602 - val_accuracy: 0.8913 - val_loss: 0.2563\n",
      "Epoch 79/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 649ms/step - accuracy: 0.9111 - loss: 0.2145 - val_accuracy: 0.8696 - val_loss: 0.2810\n",
      "Epoch 80/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 694ms/step - accuracy: 0.8907 - loss: 0.2449 - val_accuracy: 0.8848 - val_loss: 0.2590\n",
      "Epoch 81/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 653ms/step - accuracy: 0.9276 - loss: 0.2064 - val_accuracy: 0.8696 - val_loss: 0.2978\n",
      "Epoch 82/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 676ms/step - accuracy: 0.8959 - loss: 0.2422 - val_accuracy: 0.8522 - val_loss: 0.3060\n",
      "Epoch 83/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 656ms/step - accuracy: 0.9029 - loss: 0.2326 - val_accuracy: 0.8717 - val_loss: 0.2872\n",
      "Epoch 84/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 669ms/step - accuracy: 0.9070 - loss: 0.2436 - val_accuracy: 0.8761 - val_loss: 0.2811\n",
      "Epoch 85/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 701ms/step - accuracy: 0.8951 - loss: 0.2381 - val_accuracy: 0.8739 - val_loss: 0.2745\n",
      "Epoch 86/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 711ms/step - accuracy: 0.8816 - loss: 0.2725 - val_accuracy: 0.8696 - val_loss: 0.2872\n",
      "Epoch 87/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 705ms/step - accuracy: 0.9025 - loss: 0.2427 - val_accuracy: 0.8674 - val_loss: 0.2955\n",
      "Epoch 88/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 687ms/step - accuracy: 0.8995 - loss: 0.2357 - val_accuracy: 0.8783 - val_loss: 0.2768\n",
      "Epoch 89/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 706ms/step - accuracy: 0.8995 - loss: 0.2427 - val_accuracy: 0.8696 - val_loss: 0.2922\n",
      "Epoch 90/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 708ms/step - accuracy: 0.9082 - loss: 0.2285 - val_accuracy: 0.8652 - val_loss: 0.2897\n",
      "Epoch 91/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 688ms/step - accuracy: 0.9128 - loss: 0.2329 - val_accuracy: 0.8630 - val_loss: 0.3031\n",
      "Epoch 92/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 772ms/step - accuracy: 0.9022 - loss: 0.2348 - val_accuracy: 0.8848 - val_loss: 0.2669\n",
      "Epoch 93/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 736ms/step - accuracy: 0.9062 - loss: 0.2404 - val_accuracy: 0.8696 - val_loss: 0.2799\n",
      "Epoch 94/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 736ms/step - accuracy: 0.9164 - loss: 0.2129 - val_accuracy: 0.8457 - val_loss: 0.3218\n",
      "Epoch 95/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 695ms/step - accuracy: 0.8967 - loss: 0.2568 - val_accuracy: 0.8370 - val_loss: 0.3483\n",
      "Epoch 96/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 692ms/step - accuracy: 0.8763 - loss: 0.2645 - val_accuracy: 0.8652 - val_loss: 0.3047\n",
      "Epoch 97/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 693ms/step - accuracy: 0.9110 - loss: 0.2163 - val_accuracy: 0.8587 - val_loss: 0.3257\n",
      "Epoch 98/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 704ms/step - accuracy: 0.9175 - loss: 0.2098 - val_accuracy: 0.8652 - val_loss: 0.2960\n",
      "Epoch 99/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 685ms/step - accuracy: 0.9299 - loss: 0.1952 - val_accuracy: 0.8783 - val_loss: 0.2832\n",
      "Epoch 100/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 713ms/step - accuracy: 0.9106 - loss: 0.2157 - val_accuracy: 0.8717 - val_loss: 0.2967\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "mobilenet_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "mobilenet_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "mobilenet_history = mobilenet_model.fit(\n",
    "    train_data,\n",
    "    epochs=100,\n",
    "    validation_data=test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d42924-965e-4348-b709-aff056f856bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 172ms/step - accuracy: 0.5899 - loss: 0.8052\n",
      "CNN Accuracy: 59.13%\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - accuracy: 0.8617 - loss: 0.2953\n",
      "MobileNetV2 Accuracy: 87.17%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate CNN\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(test_data)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate MobileNetV2\n",
    "mobilenet_loss, mobilenet_accuracy = mobilenet_model.evaluate(test_data)\n",
    "print(f\"MobileNetV2 Accuracy: {mobilenet_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb9674e7-bd48-4326-9665-7d6607fc1a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "The car is damaged (Confidence: 78.60%)\n"
     ]
    }
   ],
   "source": [
    "def ensemble_predict(models, img_path):\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    predictions = [model.predict(img_array)[0][0] for model in models]\n",
    "    final_prediction = np.mean(predictions)\n",
    "    \n",
    "    if final_prediction > 0.5:\n",
    "        print(f\"The car is damaged (Confidence: {final_prediction * 100:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"The car is NOT damaged (Confidence: {(1 - final_prediction) * 100:.2f}%)\")\n",
    "\n",
    "# Use ensemble\n",
    "models = [mobilenet_model]\n",
    "ensemble_predict(models, \"dataset/test/damaged/0011.JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "686fb755-c45c-4ad4-9439-ed262d580ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save models\n",
    "mobilenet_model.save('mobilenet_model.h5')\n",
    "\n",
    "# Load models\n",
    "from tensorflow.keras.models import load_model\n",
    "mobilenet_model = load_model('mobilenet_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef1799-7020-44ad-80d0-50593980e402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
